{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5MSHFjLg4OhX",
      "metadata": {
        "id": "5MSHFjLg4OhX"
      },
      "source": [
        "# Video Q/A with Videoprism and Parakeet-v3\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/everettVT/daft-video-embeddings/blob/main/friction/UNFILTERED_Pt2_videoprism_parakeet.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "Videoprism is a general-purpose video encoder designed to tackle a wide spectrum of video understanding tasks, including classification localization, retrieval, captioning, and question answering.\n",
        "\n",
        "Parakeet is a 600-million-parameter multilingual automatic speech recognition (ASR) model designed for high-throughput speech-to-text transcription.\n",
        "\n",
        "In this notebook, we will explore how to leverage these foundational models to generate video and text embeddings from youtube or any video file.\n",
        "\n",
        "Video processing requires us to extract both image and audio frames, which can then use to generate embeddings. In this use case we will be transcribing the audio to text segments so we can perform RAG Q/A against both the visual and spoken content.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "kyUr_6bI8i1w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyUr_6bI8i1w",
        "outputId": "de529f1e-0796-484a-992d-c72310a5e9b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/videoprism_repo\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from videoprism==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from videoprism==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from videoprism==1.0.0) (0.8.1)\n",
            "Collecting einshape (from videoprism==1.0.0)\n",
            "  Downloading einshape-1.0-py3-none-any.whl.metadata (706 bytes)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.12/dist-packages (from videoprism==1.0.0) (0.10.6)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from videoprism==1.0.0) (0.34.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from videoprism==1.0.0) (0.2.1)\n",
            "Requirement already satisfied: tensorflow==2.19.0 in /usr/local/lib/python3.12/dist-packages (from videoprism==1.0.0) (2.19.0)\n",
            "Requirement already satisfied: tensorboard==2.19.0 in /usr/local/lib/python3.12/dist-packages (from videoprism==1.0.0) (2.19.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.19.0->videoprism==1.0.0) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.19.0->videoprism==1.0.0) (3.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.19.0->videoprism==1.0.0) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.19.0->videoprism==1.0.0) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.19.0->videoprism==1.0.0) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.19.0->videoprism==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.19.0->videoprism==1.0.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.19.0->videoprism==1.0.0) (3.1.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (3.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (2.32.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (1.17.3)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0->videoprism==1.0.0) (0.5.3)\n",
            "Requirement already satisfied: jax>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from flax->videoprism==1.0.0) (0.5.3)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from flax->videoprism==1.0.0) (1.1.1)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.12/dist-packages (from flax->videoprism==1.0.0) (0.2.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax->videoprism==1.0.0) (0.11.24)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.12/dist-packages (from flax->videoprism==1.0.0) (0.1.76)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.12/dist-packages (from flax->videoprism==1.0.0) (13.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from flax->videoprism==1.0.0) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax->videoprism==1.0.0) (0.1.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->videoprism==1.0.0) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->videoprism==1.0.0) (2025.3.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->videoprism==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->videoprism==1.0.0) (1.1.9)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.19.0->videoprism==1.0.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.3,>=0.5.3 in /usr/local/lib/python3.12/dist-packages (from jax>=0.5.1->flax->videoprism==1.0.0) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from jax>=0.5.1->flax->videoprism==1.0.0) (1.16.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0->videoprism==1.0.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0->videoprism==1.0.0) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->videoprism==1.0.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->videoprism==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->videoprism==1.0.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->videoprism==1.0.0) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax->videoprism==1.0.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax->videoprism==1.0.0) (2.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard==2.19.0->videoprism==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.12/dist-packages (from optax->flax->videoprism==1.0.0) (0.1.90)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->videoprism==1.0.0) (1.13.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->videoprism==1.0.0) (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->videoprism==1.0.0) (24.1.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->videoprism==1.0.0) (4.13.0)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax->videoprism==1.0.0) (3.20.1)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax->flax->videoprism==1.0.0) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->videoprism==1.0.0) (0.1.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->videoprism==1.0.0) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->videoprism==1.0.0) (3.23.0)\n",
            "Downloading einshape-1.0-py3-none-any.whl (21 kB)\n",
            "Building wheels for collected packages: videoprism\n",
            "  Building wheel for videoprism (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for videoprism: filename=videoprism-1.0.0-py3-none-any.whl size=40354 sha256=fb06ff841047eb215835edd1601d075d896f040c62aff1e231c492993d677f77\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8n8_whq8/wheels/e3/73/3c/3dc3551ff92b46a1e55f9a893f2d5b8fdc55d670bd73d3b605\n",
            "Successfully built videoprism\n",
            "Installing collected packages: einshape, videoprism\n",
            "Successfully installed einshape-1.0 videoprism-1.0.0\n"
          ]
        }
      ],
      "source": [
        "# @title Prepare environment\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Fetch VideoPrism repository if Python does not know about it and install\n",
        "# dependencies needed for this notebook.\n",
        "if not os.path.exists(\"videoprism_repo\"):\n",
        "  !git clone --quiet --branch=main --depth=1 \\\n",
        "     https://github.com/everettVT/videoprism.git videoprism_repo\n",
        "  os.chdir('./videoprism_repo')\n",
        "  !pip install .\n",
        "  os.chdir('..')\n",
        "\n",
        "# Append VideoPrism code to Python import path.\n",
        "if \"videoprism_repo\" not in sys.path:\n",
        "  sys.path.append(\"videoprism_repo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ryv0FnDI9ry_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ryv0FnDI9ry_",
        "outputId": "7c5e90eb-20a5-4fb7-ec3f-c329d1637232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting daft>=0.6.1\n",
            "  Downloading daft-0.6.1-cp39-abi3-manylinux_2_24_x86_64.whl.metadata (12 kB)\n",
            "Collecting av\n",
            "  Downloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.9.5-py3-none-any.whl.metadata (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax[cuda12] in /usr/local/lib/python3.12/dist-packages (0.5.3)\n",
            "Collecting nemo_toolkit[asr]\n",
            "  Downloading nemo_toolkit-2.4.0-py3-none-any.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.5/91.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from daft>=0.6.1) (18.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from daft>=0.6.1) (2025.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from daft>=0.6.1) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from daft>=0.6.1) (4.15.0)\n",
            "Requirement already satisfied: jaxlib<=0.5.3,>=0.5.3 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]) (0.5.3)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from jax[cuda12]) (1.16.1)\n",
            "Requirement already satisfied: jax-cuda12-plugin<=0.5.3,>=0.5.3 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (0.5.3)\n",
            "Collecting fsspec (from daft>=0.6.1)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.34.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.60.0)\n",
            "Collecting onnx>=1.7.0 (from nemo_toolkit[asr])\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: protobuf~=5.29.5 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.9.0.post0)\n",
            "Collecting ruamel.yaml (from nemo_toolkit[asr])\n",
            "  Downloading ruamel.yaml-0.18.15-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (75.2.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.19.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (1.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.8.0+cu126)\n",
            "Collecting wget (from nemo_toolkit[asr])\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (1.17.3)\n",
            "Collecting braceexpand (from nemo_toolkit[asr])\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.8.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.8.1)\n",
            "Collecting jiwer<4.0.0,>=3.1.0 (from nemo_toolkit[asr])\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting kaldi-python-io (from nemo_toolkit[asr])\n",
            "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lhotse!=1.31.0 (from nemo_toolkit[asr])\n",
            "  Downloading lhotse-1.30.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.11.0)\n",
            "Collecting marshmallow (from nemo_toolkit[asr])\n",
            "  Downloading marshmallow-4.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting optuna (from nemo_toolkit[asr])\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (25.0)\n",
            "Collecting pyannote.core (from nemo_toolkit[asr])\n",
            "  Downloading pyannote_core-6.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pyannote.metrics (from nemo_toolkit[asr])\n",
            "  Downloading pyannote_metrics-4.0.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.25.1)\n",
            "Collecting pyloudnorm (from nemo_toolkit[asr])\n",
            "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting resampy (from nemo_toolkit[asr])\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.13.1)\n",
            "Collecting sox<=1.5.0 (from nemo_toolkit[asr])\n",
            "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting texterrors<1.0.0 (from nemo_toolkit[asr])\n",
            "  Downloading texterrors-0.5.1.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whisper_normalizer (from nemo_toolkit[asr])\n",
            "  Downloading whisper_normalizer-0.1.12-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting num2words (from nemo_toolkit[asr])\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy>=1.25 (from jax[cuda12])\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (4.0.0)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (7.5.0)\n",
            "Collecting mediapy==1.1.6 (from nemo_toolkit[asr])\n",
            "  Downloading mediapy-1.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.2.2)\n",
            "Collecting sacremoses>=0.0.43 (from nemo_toolkit[asr])\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: sentencepiece<1.0.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.2.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (3.1.1)\n",
            "Collecting fiddle (from nemo_toolkit[asr])\n",
            "  Downloading fiddle-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting hydra-core<=1.3.2,>1.3 (from nemo_toolkit[asr])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightning<=2.4.0,>2.2.1 (from nemo_toolkit[asr])\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: omegaconf<=2.3 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (2.3.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.17.1)\n",
            "Collecting torchmetrics>=0.11.0 (from nemo_toolkit[asr])\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting transformers<=4.52.0,>=4.51.0 (from nemo_toolkit[asr])\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[asr]) (0.21.3)\n",
            "Collecting webdataset>=0.2.86 (from nemo_toolkit[asr])\n",
            "  Downloading webdataset-1.0.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting bitsandbytes==0.45.5 (from nemo_toolkit[asr])\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo_toolkit[asr]) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo_toolkit[asr]) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo_toolkit[asr]) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (3.19.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[asr]) (1.1.9)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core<=1.3.2,>1.3->nemo_toolkit[asr]) (4.9.3)\n",
            "Requirement already satisfied: jax-cuda12-pjrt==0.5.3 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin<=0.5.3,>=0.5.3->jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (0.5.3)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (12.6.80)\n",
            "Collecting nvidia-cuda-nvcc-cu12>=12.6.85 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
            "  Downloading nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.1 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12]) (12.6.85)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer<4.0.0,>=3.1.0->nemo_toolkit[asr]) (8.2.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer<4.0.0,>=3.1.0->nemo_toolkit[asr])\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo_toolkit[asr]) (3.0.1)\n",
            "Collecting cytoolz>=0.10.1 (from lhotse!=1.31.0->nemo_toolkit[asr])\n",
            "  Downloading cytoolz-1.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting intervaltree>=3.1.0 (from lhotse!=1.31.0->nemo_toolkit[asr])\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo_toolkit[asr]) (0.9.0)\n",
            "Collecting lilcom>=1.1.0 (from lhotse!=1.31.0->nemo_toolkit[asr])\n",
            "  Downloading lilcom-1.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->nemo_toolkit[asr]) (1.1.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<=2.4.0,>2.2.1->nemo_toolkit[asr])\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting packaging (from nemo_toolkit[asr])\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pytorch-lightning (from lightning<=2.4.0,>2.2.1->nemo_toolkit[asr])\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->nemo_toolkit[asr]) (0.43.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacremoses>=0.0.43->nemo_toolkit[asr]) (2024.11.6)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->nemo_toolkit[asr]) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile->nemo_toolkit[asr]) (1.17.1)\n",
            "Collecting pybind11 (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting plac (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Downloading plac-1.4.5-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting loguru (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from texterrors<1.0.0->nemo_toolkit[asr]) (3.1.0)\n",
            "Collecting Levenshtein (from texterrors<1.0.0->nemo_toolkit[asr])\n",
            "  Downloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[asr]) (3.4.0)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<=4.52.0,>=4.51.0->nemo_toolkit[asr])\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.52.0,>=4.51.0->nemo_toolkit[asr]) (0.6.2)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[asr]) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[asr]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[asr]) (0.70.16)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from fiddle->nemo_toolkit[asr]) (1.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from fiddle->nemo_toolkit[asr]) (0.21)\n",
            "Collecting libcst (from fiddle->nemo_toolkit[asr])\n",
            "  Downloading libcst-1.8.4-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect->nemo_toolkit[asr]) (10.8.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect->nemo_toolkit[asr]) (4.4.4)\n",
            "Collecting docopt>=0.6.2 (from num2words->nemo_toolkit[asr])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->nemo_toolkit[asr]) (1.16.5)\n",
            "Collecting colorlog (from optuna->nemo_toolkit[asr])\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->nemo_toolkit[asr]) (2.0.43)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->nemo_toolkit[asr]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->nemo_toolkit[asr]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->nemo_toolkit[asr]) (1.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft->nemo_toolkit[asr]) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft->nemo_toolkit[asr]) (1.10.1)\n",
            "INFO: pip is looking at multiple versions of pyannote-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pyannote.core (from nemo_toolkit[asr])\n",
            "  Downloading pyannote_core-6.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from pyannote.core->nemo_toolkit[asr]) (2.4.0)\n",
            "INFO: pip is looking at multiple versions of pyannote-metrics to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pyannote.metrics (from nemo_toolkit[asr])\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo_toolkit[asr])\n",
            "  Downloading pyannote_database-6.0.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from pyloudnorm->nemo_toolkit[asr]) (1.0.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->nemo_toolkit[asr])\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[asr]) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[asr]) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[asr]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[asr]) (3.1.3)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[asr]) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[asr]) (4.4.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[asr]) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[asr]) (2.36.0)\n",
            "Collecting indic-numtowords (from whisper_normalizer->nemo_toolkit[asr])\n",
            "  Downloading indic_numtowords-1.1.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->nemo_toolkit[asr]) (1.3.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile->nemo_toolkit[asr]) (2.22)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from cytoolz>=0.10.1->lhotse!=1.31.0->nemo_toolkit[asr]) (0.12.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (3.12.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]) (3.2.3)\n",
            "Collecting pandas (from nemo_toolkit[asr])\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is still looking at multiple versions of pyannote-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo_toolkit[asr])\n",
            "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (0.17.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->nemo_toolkit[asr]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->nemo_toolkit[asr]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->nemo_toolkit[asr]) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[asr]) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->nemo_toolkit[asr]) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->nemo_toolkit[asr]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->nemo_toolkit[asr]) (3.0.2)\n",
            "Collecting jedi>=0.16 (from ipython->mediapy==1.1.6->nemo_toolkit[asr])\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[asr]) (4.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]) (1.20.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy==1.1.6->nemo_toolkit[asr]) (0.2.13)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]) (0.1.2)\n",
            "Downloading daft-0.6.1-cp39-abi3-manylinux_2_24_x86_64.whl (47.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.9.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapy-1.1.6-py3-none-any.whl (24 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading lhotse-1.30.3-py3-none-any.whl (851 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.4/851.4 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-1.0.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading fiddle-0.3.0-py3-none-any.whl (419 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-4.0.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nemo_toolkit-2.4.0-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.15-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading whisper_normalizer-0.1.12-py3-none-any.whl (36 kB)\n",
            "Downloading cytoolz-1.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading lilcom-1.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (754 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.1/754.1 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading indic_numtowords-1.1.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcst-1.8.4-cp312-cp312-manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plac-1.4.5-py2.py3-none-any.whl (22 kB)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Downloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sox, texterrors, kaldi-python-io, wget, docopt, intervaltree\n",
            "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40036 sha256=a61636ad9bcb437971f073ed439d5f180898df3c9885a4078fc6572c2bfaf5b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c7/e7/baea1f7e79b9eb53addc81cc9b827424f4a7d8c9cc18c03659\n",
            "  Building wheel for texterrors (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for texterrors: filename=texterrors-0.5.1-cp312-cp312-linux_x86_64.whl size=1197640 sha256=b91a1515e0237c2186940c44368f2b07522e4b9f44ba6ce245f904bc5e684add\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/8f/81/7df3770dce1fcd6dc49118d4b1766f99334dd2ff43848f3893\n",
            "  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8953 sha256=beb4731a82507afcfaa597fd87ab8537d017f8f809935439bd796965f8c8cf95\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/a9/7b/af1bff74047bf7dfde7040b8fbe968ebb2f68eeed71249a14c\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=f4f34c76d26aced8911eb45c1e6269bef1773e269dc10b1bb3dc862d91e0e757\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=41bbd58b67c01af5cb4481be177d0eb5514fb1b82bb2d0ed01b784bcbfdc9495\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26098 sha256=f467689b7fc00b175ddd41b4427e8c216b16dee321b8f326bf7e2124461ba5bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/c3/c3/238bf93c243597857edd94ddb0577faa74a8e16e9585896e83\n",
            "Successfully built sox texterrors kaldi-python-io wget docopt intervaltree\n",
            "Installing collected packages: wget, plac, docopt, braceexpand, yt-dlp, sacremoses, ruamel.yaml.clib, rapidfuzz, pybind11, packaging, nvidia-cuda-nvcc-cu12, numpy, num2words, marshmallow, loguru, libcst, jedi, intervaltree, indic-numtowords, fsspec, cytoolz, colorlog, av, whisper_normalizer, webdataset, sox, ruamel.yaml, lilcom, lightning-utilities, Levenshtein, kaldi-python-io, jiwer, hydra-core, fiddle, daft, tokenizers, texterrors, resampy, pyloudnorm, pyannote.core, optuna, onnx, transformers, torchmetrics, pyannote.database, nemo_toolkit, mediapy, lhotse, bitsandbytes, pytorch-lightning, pyannote.metrics, lightning\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-cuda-nvcc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvcc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvcc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvcc-cu12-12.5.82\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.0\n",
            "    Uninstalling tokenizers-0.22.0:\n",
            "      Successfully uninstalled tokenizers-0.22.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.1\n",
            "    Uninstalling transformers-4.56.1:\n",
            "      Successfully uninstalled transformers-4.56.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Levenshtein-0.27.1 av-15.1.0 bitsandbytes-0.45.5 braceexpand-0.1.7 colorlog-6.9.0 cytoolz-1.0.1 daft-0.6.1 docopt-0.6.2 fiddle-0.3.0 fsspec-2024.12.0 hydra-core-1.3.2 indic-numtowords-1.1.0 intervaltree-3.1.0 jedi-0.19.2 jiwer-3.1.0 kaldi-python-io-1.2.2 lhotse-1.30.3 libcst-1.8.4 lightning-2.4.0 lightning-utilities-0.15.2 lilcom-1.8.1 loguru-0.7.3 marshmallow-4.0.1 mediapy-1.1.6 nemo_toolkit-2.4.0 num2words-0.5.14 numpy-1.26.4 nvidia-cuda-nvcc-cu12-12.9.86 onnx-1.19.0 optuna-4.5.0 packaging-24.2 plac-1.4.5 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pybind11-3.0.1 pyloudnorm-0.1.1 pytorch-lightning-2.5.5 rapidfuzz-3.14.1 resampy-0.4.3 ruamel.yaml-0.18.15 ruamel.yaml.clib-0.2.12 sacremoses-0.1.1 sox-1.5.0 texterrors-0.5.1 tokenizers-0.21.4 torchmetrics-1.8.2 transformers-4.51.3 webdataset-1.0.2 wget-3.2 whisper_normalizer-0.1.12 yt-dlp-2025.9.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging"
                ]
              },
              "id": "806c6fc3de3746939b151def12a22721"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install \"daft>=0.6.1\" av yt-dlp \"jax[cuda12]\" \"nemo_toolkit[asr]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2e51f7fc",
      "metadata": {
        "id": "2e51f7fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6b1d1c-a57e-41ec-ebee-9a72f0d01682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CudaDevice(id=0)]\n"
          ]
        }
      ],
      "source": [
        "import daft\n",
        "from daft import col, DataType as dt\n",
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.extend import backend\n",
        "import tensorflow as tf\n",
        "from videoprism import models as vp\n",
        "print(jax.devices())    # should list a CUDA device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fb88b8",
      "metadata": {
        "id": "00fb88b8"
      },
      "source": [
        "### Define Parameters\n",
        "\n",
        "Tensor Dimensions:\n",
        "- B: batch size (number of videos in a batch).\n",
        "- T: number of frames per video clip (typically 16).\n",
        "- N: tokens per frame (for 288×288 with 18×18 patches → 16×16 = 256).\n",
        "- D: embedding dimension (Base: 768; Large: 1024).\n",
        "\n",
        "VideoPrism supports video+text inputs and returns:\n",
        "- video_embeddings: [B, D] (global video embeddings).\n",
        "- text_embeddings: [B, D] (global text embeddings).\n",
        "- Optional: frame_embeddings [B, T, D]; tokens [B, T×N, D]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5a2b10eb",
      "metadata": {
        "id": "5a2b10eb"
      },
      "outputs": [],
      "source": [
        "B, T, H, W, C = 24, 16, 288, 288, 3\n",
        "ROW_LIMIT = 2048"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download first 5 videos from your favorite youtube playlist"
      ],
      "metadata": {
        "id": "e33_yh36P8Of"
      },
      "id": "e33_yh36P8Of"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir videos && cd videos && yt-dlp -I 1:6 https://www.youtube.com/playlist?list=PL3Q1vFKgSohNO4mbMKo5xccOsYWISUlou"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQZDKavnP6WU",
        "outputId": "379396e3-de59-409a-c5ff-8d0a4320eb90"
      },
      "id": "YQZDKavnP6WU",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube:tab] Extracting URL: https://www.youtube.com/playlist?list=PL3Q1vFKgSohNO4mbMKo5xccOsYWISUlou\n",
            "[youtube:tab] PL3Q1vFKgSohNO4mbMKo5xccOsYWISUlou: Downloading webpage\n",
            "\u001b[0;33mWARNING:\u001b[0m [youtube:tab] YouTube said: INFO - 2 unavailable videos are hidden\n",
            "[youtube:tab] PL3Q1vFKgSohNO4mbMKo5xccOsYWISUlou: Redownloading playlist API JSON with unavailable videos\n",
            "[download] Downloading playlist: Data Topic Deep Dives\n",
            "[youtube:tab] Playlist Data Topic Deep Dives: Downloading 6 items of 19\n",
            "[download] Downloading item \u001b[0;32m1\u001b[0m of \u001b[0;94m6\u001b[0m\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=WAsmZJ2kff0\n",
            "[youtube] WAsmZJ2kff0: Downloading webpage\n",
            "[youtube] WAsmZJ2kff0: Downloading tv simply player API JSON\n",
            "[youtube] WAsmZJ2kff0: Downloading tv client config\n",
            "[youtube] WAsmZJ2kff0: Downloading player 9bae1a63-main\n",
            "[youtube] WAsmZJ2kff0: Downloading tv player API JSON\n",
            "[info] WAsmZJ2kff0: Downloading 1 format(s): 303+251\n",
            "[download] Sleeping 3.00 seconds as required by the site...\n",
            "[download] Destination: GPU Pipeline Optimization Explained ｜ Async UDFs, CUDA Streams & Pinned Memory [WAsmZJ2kff0].f303.webm\n",
            "\u001b[K[download] 100% of  111.36MiB in \u001b[1;37m00:00:03\u001b[0m at \u001b[0;32m32.00MiB/s\u001b[0m\n",
            "[download] Destination: GPU Pipeline Optimization Explained ｜ Async UDFs, CUDA Streams & Pinned Memory [WAsmZJ2kff0].f251.webm\n",
            "\u001b[K[download] 100% of   16.51MiB in \u001b[1;37m00:00:01\u001b[0m at \u001b[0;32m15.21MiB/s\u001b[0m\n",
            "[Merger] Merging formats into \"GPU Pipeline Optimization Explained ｜ Async UDFs, CUDA Streams & Pinned Memory [WAsmZJ2kff0].webm\"\n",
            "Deleting original file GPU Pipeline Optimization Explained ｜ Async UDFs, CUDA Streams & Pinned Memory [WAsmZJ2kff0].f251.webm (pass -k to keep)\n",
            "Deleting original file GPU Pipeline Optimization Explained ｜ Async UDFs, CUDA Streams & Pinned Memory [WAsmZJ2kff0].f303.webm (pass -k to keep)\n",
            "[download] Downloading item \u001b[0;32m2\u001b[0m of \u001b[0;94m6\u001b[0m\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=KoQa0sD2g6Y\n",
            "[youtube] KoQa0sD2g6Y: Downloading webpage\n",
            "[youtube] KoQa0sD2g6Y: Downloading tv simply player API JSON\n",
            "[youtube] KoQa0sD2g6Y: Downloading tv client config\n",
            "[youtube] KoQa0sD2g6Y: Downloading tv player API JSON\n",
            "\u001b[0;31mERROR:\u001b[0m [youtube] KoQa0sD2g6Y: Video unavailable. This video has been removed by the uploader\n",
            "[download] Downloading item \u001b[0;32m3\u001b[0m of \u001b[0;94m6\u001b[0m\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=wKOC_w4oKO8\n",
            "[youtube] wKOC_w4oKO8: Downloading webpage\n",
            "[youtube] wKOC_w4oKO8: Downloading tv simply player API JSON\n",
            "[youtube] wKOC_w4oKO8: Downloading tv client config\n",
            "[youtube] wKOC_w4oKO8: Downloading tv player API JSON\n",
            "[info] wKOC_w4oKO8: Downloading 1 format(s): 299+251\n",
            "[download] Sleeping 4.00 seconds as required by the site...\n",
            "[download] Destination: Build Scalable Batch Inference Pipelines in 3 Lines ｜ Daft + GPT⧸vLLM [wKOC_w4oKO8].f299.mp4\n",
            "\u001b[K[download] 100% of   24.64MiB in \u001b[1;37m00:00:02\u001b[0m at \u001b[0;32m8.25MiB/s\u001b[0m\n",
            "[download] Destination: Build Scalable Batch Inference Pipelines in 3 Lines ｜ Daft + GPT⧸vLLM [wKOC_w4oKO8].f251.webm\n",
            "\u001b[K[download] 100% of    1.95MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m9.59MiB/s\u001b[0m\n",
            "[Merger] Merging formats into \"Build Scalable Batch Inference Pipelines in 3 Lines ｜ Daft + GPT⧸vLLM [wKOC_w4oKO8].mkv\"\n",
            "Deleting original file Build Scalable Batch Inference Pipelines in 3 Lines ｜ Daft + GPT⧸vLLM [wKOC_w4oKO8].f251.webm (pass -k to keep)\n",
            "Deleting original file Build Scalable Batch Inference Pipelines in 3 Lines ｜ Daft + GPT⧸vLLM [wKOC_w4oKO8].f299.mp4 (pass -k to keep)\n",
            "[download] Downloading item \u001b[0;32m4\u001b[0m of \u001b[0;94m6\u001b[0m\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=E6QDKCgbRlw\n",
            "[youtube] E6QDKCgbRlw: Downloading webpage\n",
            "[youtube] E6QDKCgbRlw: Downloading tv simply player API JSON\n",
            "[youtube] E6QDKCgbRlw: Downloading tv client config\n",
            "[youtube] E6QDKCgbRlw: Downloading tv player API JSON\n",
            "\u001b[0;31mERROR:\u001b[0m [youtube] E6QDKCgbRlw: Video unavailable. This video has been removed by the uploader\n",
            "[download] Downloading item \u001b[0;32m5\u001b[0m of \u001b[0;94m6\u001b[0m\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=WI83lRzk7YE\n",
            "[youtube] WI83lRzk7YE: Downloading webpage\n",
            "[youtube] WI83lRzk7YE: Downloading tv simply player API JSON\n",
            "[youtube] WI83lRzk7YE: Downloading tv client config\n",
            "[youtube] WI83lRzk7YE: Downloading tv player API JSON\n",
            "[info] WI83lRzk7YE: Downloading 1 format(s): 299+251\n",
            "[download] Sleeping 4.00 seconds as required by the site...\n",
            "[download] Destination: Near-100% GPU Utilization： Embedding Millions of Text Documents With Qwen3 [WI83lRzk7YE].f299.mp4\n",
            "\u001b[K[download] 100% of   33.78MiB in \u001b[1;37m00:00:02\u001b[0m at \u001b[0;32m14.21MiB/s\u001b[0m\n",
            "[download] Destination: Near-100% GPU Utilization： Embedding Millions of Text Documents With Qwen3 [WI83lRzk7YE].f251.webm\n",
            "\u001b[K[download] 100% of    2.44MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m11.89MiB/s\u001b[0m\n",
            "[Merger] Merging formats into \"Near-100% GPU Utilization： Embedding Millions of Text Documents With Qwen3 [WI83lRzk7YE].mkv\"\n",
            "Deleting original file Near-100% GPU Utilization： Embedding Millions of Text Documents With Qwen3 [WI83lRzk7YE].f299.mp4 (pass -k to keep)\n",
            "Deleting original file Near-100% GPU Utilization： Embedding Millions of Text Documents With Qwen3 [WI83lRzk7YE].f251.webm (pass -k to keep)\n",
            "[download] Downloading item \u001b[0;32m6\u001b[0m of \u001b[0;94m6\u001b[0m\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=4CGQ-c7iivg\n",
            "[youtube] 4CGQ-c7iivg: Downloading webpage\n",
            "[youtube] 4CGQ-c7iivg: Downloading tv simply player API JSON\n",
            "[youtube] 4CGQ-c7iivg: Downloading tv client config\n",
            "[youtube] 4CGQ-c7iivg: Downloading tv player API JSON\n",
            "[info] 4CGQ-c7iivg: Downloading 1 format(s): 299+251\n",
            "[download] Sleeping 4.00 seconds as required by the site...\n",
            "[download] Destination: Why Your Image Processing Pipeline Keeps Running Out of Memory [4CGQ-c7iivg].f299.mp4\n",
            "\u001b[K[download] 100% of   31.79MiB in \u001b[1;37m00:00:02\u001b[0m at \u001b[0;32m10.84MiB/s\u001b[0m\n",
            "[download] Destination: Why Your Image Processing Pipeline Keeps Running Out of Memory [4CGQ-c7iivg].f251.webm\n",
            "\u001b[K[download] 100% of    2.65MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m3.21MiB/s\u001b[0m\n",
            "[Merger] Merging formats into \"Why Your Image Processing Pipeline Keeps Running Out of Memory [4CGQ-c7iivg].mkv\"\n",
            "Deleting original file Why Your Image Processing Pipeline Keeps Running Out of Memory [4CGQ-c7iivg].f299.mp4 (pass -k to keep)\n",
            "Deleting original file Why Your Image Processing Pipeline Keeps Running Out of Memory [4CGQ-c7iivg].f251.webm (pass -k to keep)\n",
            "[download] Finished downloading playlist: Data Topic Deep Dives\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discover the file paths"
      ],
      "metadata": {
        "id": "CCcbC7e3QUpC"
      },
      "id": "CCcbC7e3QUpC"
    },
    {
      "cell_type": "code",
      "source": [
        "from daft.functions import file\n",
        "df_files = daft.from_glob_path(\"/content/videos\").with_column(\"file\", file(col(\"path\")))\n",
        "df_files.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "w9xNHuhYQTeV",
        "outputId": "f3552239-20a7-4bd8-9793-b1e9ee93c223"
      },
      "id": "w9xNHuhYQTeV",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "        .dashboard-container {\n",
              "            display: flex;\n",
              "            gap: 20px;\n",
              "            max-width: 100%;\n",
              "            height: 100%;\n",
              "        }\n",
              "        .table-container {\n",
              "            flex: 1;\n",
              "            overflow: auto;\n",
              "        }\n",
              "        .side-pane {\n",
              "            width: 35%;\n",
              "            max-height: 500px;\n",
              "            border: 1px solid;\n",
              "            border-radius: 4px;\n",
              "            padding: 15px;\n",
              "            display: none;\n",
              "            overflow: auto;\n",
              "        }\n",
              "        .side-pane.visible {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "        }\n",
              "        .side-pane-header {\n",
              "            display: flex;\n",
              "            justify-content: space-between;\n",
              "            align-items: center;\n",
              "            margin-bottom: 10px;\n",
              "            padding-bottom: 10px;\n",
              "            border-bottom: 1px solid;\n",
              "        }\n",
              "        .side-pane-title {\n",
              "            font-weight: bold;\n",
              "        }\n",
              "        .close-button {\n",
              "            cursor: pointer;\n",
              "        }\n",
              "        .side-pane-content {\n",
              "            word-wrap: break-word;\n",
              "            overflow: auto;\n",
              "        }\n",
              "        .dataframe td.clickable {\n",
              "            cursor: pointer;\n",
              "            transition: background-color 0.2s;\n",
              "        }\n",
              "        .dataframe td.clickable:hover {\n",
              "            opacity: 0.8;\n",
              "        }\n",
              "        .dataframe td.clickable.selected {\n",
              "            opacity: 0.6;\n",
              "        }\n",
              "        </style>\n",
              "        <div class=\"dashboard-container\">\n",
              "            <div class=\"table-container\">\n",
              "        <div id=\"dataframe-856a93c3-ba53-4ec3-9904-115b5c6cdd03\"><table class=\"dataframe\" style=\"table-layout: fixed; min-width: 100%\">\n",
              "<thead><tr><th style=\"text-wrap: nowrap; width: calc(100vw / 4); min-width: 192px; overflow: hidden; text-overflow: ellipsis; text-align:left\">path<br />Utf8</th><th style=\"text-wrap: nowrap; width: calc(100vw / 4); min-width: 192px; overflow: hidden; text-overflow: ellipsis; text-align:left\">size<br />Int64</th><th style=\"text-wrap: nowrap; width: calc(100vw / 4); min-width: 192px; overflow: hidden; text-overflow: ellipsis; text-align:left\">num_rows<br />Int64</th><th style=\"text-wrap: nowrap; width: calc(100vw / 4); min-width: 192px; overflow: hidden; text-overflow: ellipsis; text-align:left\">file<br />File</th></tr></thead>\n",
              "<tbody>\n",
              "<tr><td data-row=\"0\" data-col=\"0\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">file:///content/videos/Why Your Image Processing Pipeline Keeps Running Out of Memory [4CGQ-c7iivg].mkv</div></td><td data-row=\"0\" data-col=\"1\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">36050736</div></td><td data-row=\"0\" data-col=\"2\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">None</div></td><td data-row=\"0\" data-col=\"3\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">File(Reference(\"file:///content/videos/Why Your Image Processing Pipeline Keeps Running Out of Memory [4CGQ-c7iivg].mkv\", None))</div></td></tr>\n",
              "<tr><td data-row=\"1\" data-col=\"0\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">file:///content/videos/Build Scalable Batch Inference Pipelines in 3 Lines ｜ Daft + GPT⧸vLLM [wKOC_w4oKO8].mkv</div></td><td data-row=\"1\" data-col=\"1\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">27825597</div></td><td data-row=\"1\" data-col=\"2\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">None</div></td><td data-row=\"1\" data-col=\"3\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">File(Reference(\"file:///content/videos/Build Scalable Batch Inference Pipelines in 3 Lines ｜ Daft + GPT⧸vLLM [wKOC_w4oKO8].mkv\", None))</div></td></tr>\n",
              "<tr><td data-row=\"2\" data-col=\"0\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">file:///content/videos/GPU Pipeline Optimization Explained ｜ Async UDFs, CUDA Streams &amp; Pinned Memory [WAsmZJ2kff0].webm</div></td><td data-row=\"2\" data-col=\"1\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">134080404</div></td><td data-row=\"2\" data-col=\"2\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">None</div></td><td data-row=\"2\" data-col=\"3\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">File(Reference(\"file:///content/videos/GPU Pipeline Optimization Explained ｜ Async UDFs, CUDA Streams &amp; Pinned Memory [WAsmZJ2kff0].webm\", None))</div></td></tr>\n",
              "<tr><td data-row=\"3\" data-col=\"0\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">file:///content/videos/Near-100% GPU Utilization： Embedding Millions of Text Documents With Qwen3 [WI83lRzk7YE].mkv</div></td><td data-row=\"3\" data-col=\"1\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">37924770</div></td><td data-row=\"3\" data-col=\"2\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">None</div></td><td data-row=\"3\" data-col=\"3\"><div style=\"text-align:left; width: calc(100vw / 4); min-width: 192px; max-height: 100px; overflow: hidden; text-overflow: ellipsis; word-wrap: break-word; overflow-y: auto\">File(Reference(\"file:///content/videos/Near-100% GPU Utilization： Embedding Millions of Text Documents With Qwen3 [WI83lRzk7YE].mkv\", None))</div></td></tr>\n",
              "</tbody>\n",
              "</table></div>\n",
              "            </div>\n",
              "            <div class=\"side-pane\" id=\"side-pane-856a93c3-ba53-4ec3-9904-115b5c6cdd03\">\n",
              "                <div class=\"side-pane-header\">\n",
              "                    <div class=\"side-pane-title\" id=\"side-pane-title-856a93c3-ba53-4ec3-9904-115b5c6cdd03\">Cell Details</div>\n",
              "                    <button class=\"close-button\" id=\"close-button-856a93c3-ba53-4ec3-9904-115b5c6cdd03\">×</button>\n",
              "                </div>\n",
              "                <div class=\"side-pane-content\" id=\"side-pane-content-856a93c3-ba53-4ec3-9904-115b5c6cdd03\">\n",
              "                    <p style=\"font-style: italic;\">Click on a cell to view its full content</p>\n",
              "                </div>\n",
              "            </div>\n",
              "        </div>\n",
              "    \n",
              "        <script>\n",
              "        (function() {\n",
              "            const serverUrl = 'http://127.0.0.1:3238';\n",
              "            const dfId = '856a93c3-ba53-4ec3-9904-115b5c6cdd03';\n",
              "            const dataframeElement = document.getElementById('dataframe-' + dfId);\n",
              "            const cells = dataframeElement ? dataframeElement.querySelectorAll('td') : [];\n",
              "            const sidePane = document.getElementById('side-pane-' + dfId);\n",
              "            const sidePaneTitle = document.getElementById('side-pane-title-' + dfId);\n",
              "            const sidePaneContent = document.getElementById('side-pane-content-' + dfId);\n",
              "            const closeButton = document.getElementById('close-button-' + dfId);\n",
              "            let selectedCell = null;\n",
              "\n",
              "            function closeSidePane(paneId) {\n",
              "                const pane = document.getElementById('side-pane-' + paneId);\n",
              "                if (pane) {\n",
              "                    pane.classList.remove('visible');\n",
              "                    if (selectedCell) {\n",
              "                        selectedCell.classList.remove('selected');\n",
              "                        selectedCell = null;\n",
              "                    }\n",
              "                }\n",
              "            }\n",
              "\n",
              "            function showSidePane(row, col, content) {\n",
              "                sidePaneTitle.textContent = 'Cell (' + row + ', ' + col + ')';\n",
              "                sidePaneContent.innerHTML = content;\n",
              "                sidePane.classList.add('visible');\n",
              "            }\n",
              "\n",
              "            function showLoadingContent() {\n",
              "                sidePaneContent.innerHTML = '<div style=\"text-align:center; padding:20px;\"><span style=\"font-style:italic\">Loading full content...</span></div>';\n",
              "            }\n",
              "\n",
              "            // Add event listener for close button\n",
              "            if (closeButton) {\n",
              "                closeButton.addEventListener('click', function() {\n",
              "                    closeSidePane(dfId);\n",
              "                });\n",
              "            }\n",
              "\n",
              "            cells.forEach((cell) => {\n",
              "                // Skip cells that do not have data-row and data-col attributes (e.g., ellipsis row)\n",
              "                const rowAttr = cell.getAttribute('data-row');\n",
              "                const colAttr = cell.getAttribute('data-col');\n",
              "                if (rowAttr === null || colAttr === null) return;\n",
              "\n",
              "                const row = parseInt(rowAttr);\n",
              "                const col = parseInt(colAttr);\n",
              "                cell.classList.add('clickable');\n",
              "\n",
              "                cell.onclick = function() {\n",
              "                    // Remove selection from previously selected cell\n",
              "                    if (selectedCell && selectedCell !== cell) {\n",
              "                        selectedCell.classList.remove('selected');\n",
              "                    }\n",
              "\n",
              "                    // Toggle selection for current cell\n",
              "                    if (selectedCell === cell) {\n",
              "                        cell.classList.remove('selected');\n",
              "                        selectedCell = null;\n",
              "                        closeSidePane(dfId);\n",
              "                        return;\n",
              "                    } else {\n",
              "                        cell.classList.add('selected');\n",
              "                        selectedCell = cell;\n",
              "                    }\n",
              "\n",
              "                    // Show the side pane immediately\n",
              "                    showSidePane(row, col, '');\n",
              "\n",
              "                    // Set a timeout to show loading content after 1 second\n",
              "                    const loadingTimeout = setTimeout(() => {\n",
              "                        showLoadingContent();\n",
              "                    }, 100);\n",
              "\n",
              "                    // Fetch the cell content\n",
              "                    fetch(serverUrl + '/api/dataframes/' + dfId + '/cell?row=' + row + '&col=' + col)\n",
              "                        .then(response => response.json())\n",
              "                        .then(data => {\n",
              "                            clearTimeout(loadingTimeout);\n",
              "                            showSidePane(row, col, data.value);\n",
              "                        })\n",
              "                        .catch(err => {\n",
              "                            clearTimeout(loadingTimeout);\n",
              "                            // Get the original cell content from the table\n",
              "                            const cell = selectedCell;\n",
              "                            if (cell) {\n",
              "                                const originalContent = cell.innerHTML;\n",
              "                                showSidePane(row, col, originalContent);\n",
              "                            }\n",
              "                        });\n",
              "                };\n",
              "            });\n",
              "        })();\n",
              "        </script>\n",
              "        \n",
              "<small>(Showing first 4 of 4 rows)</small>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Get Video File Metadata"
      ],
      "metadata": {
        "id": "nNv4NAv7T-Wz"
      },
      "id": "nNv4NAv7T-Wz"
    },
    {
      "cell_type": "code",
      "source": [
        "import av\n",
        "with av.open(\"file:///content/videos/Near-100% GPU Utilization： Embedding Millions of Text Documents With Qwen3 [WI83lRzk7YE].mkv\") as container:\n",
        "    for frame in container.decode(video=0):\n",
        "        print(frame.duration)\n",
        "        print(frame.time_base)\n",
        "        print(frame.dts)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7RMTjXsXB4w",
        "outputId": "dee624e9-876d-4b5f-ce98-d6e78d430db4"
      },
      "id": "i7RMTjXsXB4w",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "1/1000\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@daft.func(return_dtype=dt.struct({\n",
        "    \"width\": dt.int32(),\n",
        "    \"height\": dt.int32(),\n",
        "    \"frames\": dt.int64(),\n",
        "    \"FPS\": dt.int32()\n",
        "}))\n",
        "def read_video_metadata(file: daft.File):\n",
        "    import av\n",
        "    container = av.open(file)\n",
        "    metadata = {\n",
        "        \"width\": container.streams.video[0].width,\n",
        "        \"height\": container.streams.video[0].height,\n",
        "        \"frame_count\": container.streams.video[0].frames,\n",
        "        \"duration\": container.streams.video[0].\n",
        "    }\n",
        "    return metadata"
      ],
      "metadata": {
        "id": "fTY4uaNIT9xF"
      },
      "id": "fTY4uaNIT9xF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_meta = df_files.with_column(\"metadata\", read_video_metadata(df_files[\"file\"])).collect()\n",
        "df_meta.show(5)"
      ],
      "metadata": {
        "id": "Unvx48pwVTxS"
      },
      "id": "Unvx48pwVTxS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "xcEeeY8DRRQq",
      "metadata": {
        "id": "xcEeeY8DRRQq"
      },
      "source": [
        "Extract Audio from Video, Transcribe and Embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "655d2593",
      "metadata": {
        "id": "655d2593"
      },
      "outputs": [],
      "source": [
        "import av\n",
        "from av.audio.resampler import AudioResampler\n",
        "\n",
        "@daft.func()\n",
        "def extract_audio_frames_into_numpy_arrays(file: daft.File) -> np.ndarray:\n",
        "\n",
        "    container = av.open(file)\n",
        "    resampler = AudioResampler(format='s16', layout='mono', rate=16000)\n",
        "\n",
        "    chunks = []\n",
        "    try:\n",
        "        for frame in container.decode(audio=0):\n",
        "            # Resample to desired SR/mono/PCM16; result can be a frame or list of frames\n",
        "            res = resampler.resample(frame)\n",
        "            frames = res if isinstance(res, (list, tuple)) else [res]\n",
        "\n",
        "            for f in frames:\n",
        "                arr = f.to_ndarray()  # typically (channels, samples) or (samples,)\n",
        "                arr = np.asarray(arr)\n",
        "\n",
        "                # Flatten to 1-D mono\n",
        "                if arr.ndim == 2:\n",
        "                    # (1, N) or (N, 1) → (N,)\n",
        "                    if arr.shape[0] == 1:\n",
        "                        arr = arr[0]\n",
        "                    elif arr.shape[1] == 1:\n",
        "                        arr = arr[:, 0]\n",
        "                    else:\n",
        "                        # Unexpected multi-channel after mono resample: average as fallback\n",
        "                        arr = arr.mean(axis=0)\n",
        "                elif arr.ndim > 2:\n",
        "                    arr = arr.reshape(-1)\n",
        "\n",
        "                # Convert PCM16 → float32 in [-1, 1]\n",
        "                if arr.dtype != np.float32:\n",
        "                    arr = (arr.astype(np.float32) / 32768.0).clip(-1.0, 1.0)\n",
        "\n",
        "                chunks.append(arr)\n",
        "    finally:\n",
        "        container.close()\n",
        "\n",
        "    if not chunks:\n",
        "        return np.zeros((0,), dtype=np.float32)\n",
        "\n",
        "    audio = np.concatenate(chunks, axis=0).astype(np.float32, copy=False)\n",
        "    return audio\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddce0e7",
      "metadata": {
        "id": "3ddce0e7"
      },
      "outputs": [],
      "source": [
        "@daft.udf(return_dtype = dt.string())\n",
        "class ParakeetTranscribeUDF:\n",
        "    def __init__(self, context_size: int = 256):\n",
        "        import nemo.collections.asr as nemo_asr\n",
        "        self.asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name=\"nvidia/parakeet-tdt-0.6b-v3\")\n",
        "        self.asr_model.change_attention_model(\n",
        "            self_attention_model=\"rel_pos_local_attn\",\n",
        "            att_context_size=[context_size, context_size]\n",
        "        )\n",
        "\n",
        "    def __call__(self, audio: list[np.ndarray]):\n",
        "        outputs = self.asr_model.transcribe(audio)\n",
        "        texts = [o.text for o in outputs]\n",
        "        return texts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e1bc0c",
      "metadata": {
        "id": "a0e1bc0c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Parakeet Transcribe with Timestamps\n",
        "@daft.udf(return_dtype = dt.struct({\n",
        "    \"segment\": dt.list(dt.struct({\n",
        "        \"start_offset\": dt.int32(),\n",
        "        \"end_offset\": dt.int32(),\n",
        "        \"start\": dt.float32(),\n",
        "        \"end\": dt.float32()\n",
        "    })),\n",
        "}))\n",
        "class ParakeetTranscribeTimestampsUDF:\n",
        "    def __init__(self, context_size: int = 256):\n",
        "        import nemo.collections.asr as nemo_asr\n",
        "        self.asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name=\"nvidia/parakeet-tdt-0.6b-v3\")\n",
        "        self.asr_model.change_attention_model(\n",
        "            self_attention_model=\"rel_pos_local_attn\",\n",
        "            att_context_size=[context_size, context_size]\n",
        "        )\n",
        "\n",
        "    def __call__(self, audio: list[np.ndarray]):\n",
        "        outputs = self.asr_model.transcribe(audio, timestamps=True)   # No public flag to emit only segments\n",
        "        return [o.timestamp[\"segment\"] for o in outputs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qBF-KLZ4H-et",
      "metadata": {
        "id": "qBF-KLZ4H-et"
      },
      "outputs": [],
      "source": [
        "@daft.udf(\n",
        "    return_dtype = dt.embedding(dt.float32(), 768),\n",
        "    batch_size=B, # clips per batch (tune for throughput)\n",
        "    num_gpus=1,\n",
        ")\n",
        "class VideoPrismTextUDF:\n",
        "    def __init__(self, model_name: str = \"videoprism_lvt_public_v1_base\"):\n",
        "        from videoprism import models as vp\n",
        "        self.model = vp.get_model(model_name)\n",
        "        self.params = vp.load_pretrained_weights(model_name)\n",
        "        self.text_tokenizer = vp.load_text_tokenizer('c4_en')\n",
        "\n",
        "        @jax.jit\n",
        "        def vf_b(text_ids, text_paddings):  # [B,T,288,288,3] -> [B,D]\n",
        "            _, t, _ = self.model.apply(self.params, None, text_ids, text_paddings, train=False)\n",
        "            return t # text embeddings\n",
        "\n",
        "        self.vf_b = vf_b\n",
        "\n",
        "        # Warmup both\n",
        "        text_ids, text_paddings = vp.tokenize_texts(self.text_tokenizer, [\"Hello\", \"World\"])\n",
        "        _ = self.vf_b(None, text_ids, text_paddings).block_until_ready()\n",
        "\n",
        "    def __call__(self,\n",
        "        prompts: list[str], # List[T,H,W,C] of len B\n",
        "    ):\n",
        "        # Batch Inference\n",
        "        text_ids, text_paddings = vp.tokenize_texts(self.text_tokenizer, prompts)\n",
        "        text_embeddings = self.vf_b(text_ids, text_paddings)\n",
        "\n",
        "        return text_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e51240",
      "metadata": {
        "id": "84e51240"
      },
      "source": [
        "# Using daft.File instead of read_video_frames()\n",
        "\n",
        "Video data, as a critical type of multimodal data, uniquely integrates visual, audio, and temporal dimensions, inherently fusing spatial (image-based) and temporal information. It has been widely adopted across domains including short-video platforms, live streaming, public security, healthcare, and autonomous driving.\n",
        "\n",
        "Given the large volume of video data, most processing paradigms typically involve streaming-based reading and processing to minimize memory footprint. This distinguishes it from image data, which generally requires full initial loading into memory prior to processing.\n",
        "\n",
        "Thus, when introducing the Video data type into Daft, it should avoid storing the entire dataset in memory. Drawing inspiration from the File data type, we can either store merely a URL reference to the video data or directly utilize the underlying data structure of the File data type as its internal representation.\n",
        "\n",
        "Beyond the core content of video data, it is critical to extract key metadata to facilitate subsequent filtering of target videos prior to processing. Videos encompass extensive metadata, such as frame count, resolution (height/width), time base, duration, pixel format, bit rate, codec name, and profile, among others. However, incorporating all such metadata into the Video data type is impractical from a memory efficiency standpoint. Instead, we prioritize including only essential metadata fields—specifically frame count, height, width, and FPS. Additional metadata can be dynamically retrieved during video processing as needed.\n",
        "\n",
        "\n",
        "- support using different algorithms to reading/extracting accurate key frames, e.g. difference, optical flow, the default behavior of PyAV to extract key frame is based on I-frame the use the native encoding metadata pict_type='I'\n",
        "\n",
        "- Besides extracting/reading key frames, there are other use case about video, e.g. split video by key frame, extract audio from video, etc.\n",
        "\n",
        " it's better to add these functions on Video or file data type instead of adding new API for each use cases.\n",
        "\n",
        "From performance perspective, it's better to use rust library to handle video processing logical as much as possible, e.g. ffmpeg-next, even though most tools are based on ffmepg filter/pushdown video data based on thier metadata before processing them.\n",
        "\n",
        "\n",
        "\n",
        "R Conner Howell\n",
        ":daft:  Aug 28th at 11:07 AM\n",
        "I agree. The idea behind the \"File\" type was to start with a wrapper of the appropriate python file-like protocols, then to further type into VideoFile, AudioFile, PdfFile, etc. — each of which having their own domain-specific methods such a read_frames, read_channels, read_pages etc. respectively. As you have also pointed out, this enables daft to implement this functionality in Rust as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d938a8d",
      "metadata": {
        "id": "6d938a8d"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = df.from_glob_path(\"s3://bucket/videos/\")\n",
        "\n",
        "# Convert path to video directly from utf8 data type to video type. Daft should support convert from utf8 and file data type both.\n",
        "df = df.with_column(\"video\", video(col(\"path\")))\n",
        "\n",
        "# Filter video by video metadata.\n",
        "df = df.filter((df[\"width\"] > 1024) & (df[\"height\"] > 576) & (df[\"frames\"] > 100)))\n",
        "\n",
        "# Extract the key frames, the `key_frames` function will streaming read video data\n",
        "# and extract multiple key frames, the data type of each frame is FixedShapeImage. The `key_frames` might add more parameters to indicate what's the image mode of key frames.\n",
        "# TODO consider whether to include some metadata for key frame to compatible with daft.read_video_frames\n",
        "df = df.with_column(\"key_frames\", key_frames(col(\"video\"), method= \"I_frame\").explode(\"key_frames\")\n",
        "\n",
        "# Save the key frames as a dataset.\n",
        "df.select(\"path\", \"key_frames\").write_lance(\"key_frames_dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84241731",
      "metadata": {
        "id": "84241731"
      },
      "source": [
        "### Read Video Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9375a9b",
      "metadata": {
        "id": "d9375a9b"
      },
      "outputs": [],
      "source": [
        "df_video_frames = daft.read_video_frames(\n",
        "    df_files[\"path\"],\n",
        "    image_height=H,\n",
        "    image_width=W,\n",
        ").limit(ROW_LIMIT).collect()\n",
        "df_frames.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5682fe50",
      "metadata": {
        "id": "5682fe50"
      },
      "source": [
        "### Group Frames into Clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e6833b4",
      "metadata": {
        "id": "0e6833b4"
      },
      "outputs": [],
      "source": [
        "df_grouped = (\n",
        "    df_video_frames\n",
        "    .with_column(\"group_index\", df_frames[\"frame_index\"] // T)\n",
        "    .groupby(\"path\", \"group_index\")\n",
        "    .agg_list(\"data\", \"frame_index\")\n",
        ")\n",
        "df_grouped.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96cb62e2",
      "metadata": {
        "id": "96cb62e2"
      },
      "source": [
        "### Stack, Normalize, and Cast Frames into Clip Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9e4282",
      "metadata": {
        "id": "3a9e4282"
      },
      "outputs": [],
      "source": [
        "@daft.func(return_dtype=dt.tensor(dt.float32(), shape=(16,288, 288, 3)))\n",
        "def stack_clip(frames: list[np.ndarray], indices: list[int], clip_size: int):\n",
        "    \"\"\"Stacks a list of frames into a single numpy array\n",
        "\n",
        "    Args:\n",
        "        frames: List[T] of (H,W,3) float32\n",
        "        indices: List[T] of int\n",
        "\n",
        "    Returns:\n",
        "        (1,T,H,W,3) float32 in [0,1]\n",
        "\n",
        "    In a parallel/distributed groupby, a pre-group sort isn’t guaranteed\n",
        "    to survive aggregation order; partitions can concatenate in\n",
        "    non-deterministic order. Additionally, the image dtype is natively a\n",
        "    list[uint8], so we need to cast to float32 before normalizing from\n",
        "    [0,255] to [0,1].\n",
        "\n",
        "    Steps:\n",
        "    1. Aggregate both image_tensor and frame_index.\n",
        "    2. Sort by frame_index inside the group-level UDF, then stack.\n",
        "    3. Normalize and cast in one step.\n",
        "    4. Add a batch dimension and return.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Don't assume frames are sorted already:\n",
        "    order = np.argsort(np.asarray(indices))\n",
        "\n",
        "    # Convert Daft Image to np.ndarray\n",
        "    def to_np(x):\n",
        "        if hasattr(x, \"to_numpy\"):\n",
        "            return x.to_numpy()          # Daft Image -> np.ndarray (H,W,C) uint8\n",
        "        return np.asarray(x)\n",
        "\n",
        "    # Sort frames by frame_index\n",
        "    frames_sorted = [to_np(frames[i]) for i in order]\n",
        "\n",
        "    # Ensure Tails are padded with duplicates\n",
        "    if len(order) < clip_size:\n",
        "        frames_sorted.extend([frames_sorted[-1]] * (clip_size - len(order)))\n",
        "\n",
        "    # Stack, Normalize, and Cast in one step\n",
        "    x = np.stack(frames_sorted[:clip_size], axis=0).astype(np.float32) / 255.0 # (T,H,W,3) float32 in [0,1]\n",
        "\n",
        "    return x # [1,T,H,W,C] where T=clip_size\n",
        "\n",
        "df_clips = df_grouped.with_column(\"clip\", stack_clip(df_grouped[\"data\"], df_grouped[\"frame_index\"], clip_size=T))\n",
        "df_clips.show(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f73ead73",
      "metadata": {
        "id": "f73ead73"
      },
      "source": [
        "### Define Inference Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88c0dd8a",
      "metadata": {
        "id": "88c0dd8a"
      },
      "outputs": [],
      "source": [
        "@daft.udf(\n",
        "    return_dtype = dt.embedding(dt.float32(), 768),\n",
        "    batch_size=B, # clips per batch (tune for throughput)\n",
        "    num_gpus=1,\n",
        ")\n",
        "class VideoPrismVideoUDF:\n",
        "    def __init__(self, model_name: str = \"videoprism_lvt_public_v1_base\"):\n",
        "        \"for 'videoprism_lvt_public_v1_large', set T = 8\"\n",
        "\n",
        "        from videoprism import models as vp\n",
        "        self.model = vp.get_model(model_name)\n",
        "        self.params = vp.load_pretrained_weights(model_name)\n",
        "\n",
        "        @jax.jit\n",
        "        def vf_b(clips):  # [B,T,288,288,3] -> [B,D]\n",
        "            v, _, _ = self.model.apply(\n",
        "                self.params,\n",
        "                clips,\n",
        "                None,\n",
        "                None,\n",
        "                train=False\n",
        "            )\n",
        "            return v\n",
        "\n",
        "        self.vf_b = vf_b\n",
        "\n",
        "        # Warmup both\n",
        "        _ = self.vf_b(jnp.zeros((B, T, H, W, C), jnp.float32)).block_until_ready()\n",
        "\n",
        "    def __call__(self,\n",
        "        clips: list[np.ndarray], # List[T,H,W,C] of len B\n",
        "    ):\n",
        "        # Batch Inference\n",
        "        xb = jnp.stack(clips, axis=0) # [B,T,H,W,C]\n",
        "        video_embeddings = self.vf_b(xb) # [B,768]\n",
        "        np_embeddings = np.asarray(video_embeddings)  # Back to NumPy\n",
        "        return [np_embeddings[i].tolist() for i in range(B)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gNx0eBzCQV7R",
      "metadata": {
        "id": "gNx0eBzCQV7R"
      },
      "source": [
        "Previous runs with 24 batches of 16 frame clips processed in 128 sec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2a5712b",
      "metadata": {
        "id": "e2a5712b"
      },
      "outputs": [],
      "source": [
        "print(f\"Video Embeddings will process {B} clips of {T} frame each at {W}x{H}x{3}\")\n",
        "\n",
        "df_clips_few = df_clips.sort(\"group_index\").collect()\n",
        "df_video_embs = df_clips_few.with_column(\"video_embeddings\", VideoPrismVideoUDF(df_clips_few[\"clip\"])).collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nb5h4MpIFbn0",
      "metadata": {
        "id": "nb5h4MpIFbn0"
      },
      "outputs": [],
      "source": [
        "df_video_embs.select(\"group_index\",\"video_embeddings\", \"clip\").count_rows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4691d0da",
      "metadata": {
        "id": "4691d0da"
      },
      "source": [
        "## Appendix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be80a58",
      "metadata": {
        "id": "3be80a58"
      },
      "outputs": [],
      "source": [
        "# Parakeet Transcribe with Timestamps\n",
        "@daft.udf(return_dtype = dt.struct({\n",
        "    \"word\": dt.list(dt.struct({\n",
        "        \"word\": dt.string(),\n",
        "        \"start_offset\": dt.int32(),\n",
        "        \"end_offset\": dt.int32(),\n",
        "        \"start\": dt.float32(),\n",
        "        \"end\": dt.float32()\n",
        "    })),\n",
        "    \"segment\": dt.list(dt.struct({\n",
        "        \"start_offset\": dt.int32(),\n",
        "        \"end_offset\": dt.int32(),\n",
        "        \"start\": dt.float32(),\n",
        "        \"end\": dt.float32()\n",
        "    })),\n",
        "    \"char\": dt.list(dt.struct({\n",
        "        \"char\": dt.string(),\n",
        "        \"start_offset\": dt.int32(),\n",
        "        \"end_offset\": dt.int32(),\n",
        "        \"start\": dt.float32(),\n",
        "        \"end\": dt.float32()\n",
        "    })),\n",
        "}))\n",
        "class ParakeetTranscribeTimestampsUDF:\n",
        "    def __init__(self, context_size: int = 256):\n",
        "        import nemo.collections.asr as nemo_asr\n",
        "        self.asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name=\"nvidia/parakeet-tdt-0.6b-v3\")\n",
        "        self.asr_model.change_attention_model(\n",
        "            self_attention_model=\"rel_pos_local_attn\",\n",
        "            att_context_size=[context_size, context_size]\n",
        "        )\n",
        "\n",
        "    def __call__(self, audio: list[np.ndarray]):\n",
        "        outputs = self.asr_model.transcribe(audio, timestamps=True)   # No public flag to emit only segments\n",
        "        return [o.timestamp for o in outputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19ab5926",
      "metadata": {
        "id": "19ab5926"
      },
      "outputs": [],
      "source": [
        "class DiarizationSortFormerUDF:\n",
        "    def __init__(self, context_size: int = 256):\n",
        "        from nemo.collections.asr.models import SortformerEncLabelModel\n",
        "        self.diar_model = SortformerEncLabelModel.from_pretrained(\"nvidia/diar_streaming_sortformer_4spk-v2\")\n",
        "        self.diar_model.eval() # Switch to inference mode\n",
        "\n",
        "    def __call__(self, audio: list[np.ndarray]):\n",
        "        outputs = self.asr_model.transcribe(audio, timestamps=True)   # No public flag to emit only segments\n",
        "        return [o.timestamp for o in outputs]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d0e09c6"
      },
      "source": [
        "import av\n",
        "\n",
        "probe_info = av.probe(\"/content/Near-100% GPU Utilization： Embedding Millions of Text Documents With Qwen3 [WI83lRzk7YE].mkv\")\n",
        "print(probe_info)"
      ],
      "id": "4d0e09c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljf7xZ-hXkl9"
      },
      "id": "ljf7xZ-hXkl9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}